{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/UDEA-Esp-Analitica-y-Ciencia-de-Datos/EACD-04-MACHINE-LEARNING-1/blob/master/13-%5BTALLER%5D_Validación_y_seleccion_de_modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\n",
    "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras alamancenar tu progreso**\n",
    "\n",
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-cache -O init.py -q https://raw.githubusercontent.com/UDEA-Esp-Analitica-y-Ciencia-de-Datos/EACD-04-MACHINE-LEARNING-1/master/init.py\n",
    "import init; init.init(force_download=False); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller - Parte 1\n",
    "\n",
    "**Desbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Contextualización del problema\n",
    "\n",
    "\n",
    "Usaremos el dataset Bank Marketing para el problema de clasificación. En el repositorio del UCI se encuentra más información en el siguiente [link](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('local/data/bank-additional.csv',sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el tamaño de la base de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo está distribuida la variable de salida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codifiquemos las variables categóricas para usarlas en el entrenamiento de los modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['age','campaign','duration','pdays','previous','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df2, pd.get_dummies(df[\"education\"],prefix='education',drop_first=True)], axis=1)\n",
    "df2 = pd.concat([df2, pd.get_dummies(df[\"marital\"],prefix='marital',drop_first=True)], axis=1)\n",
    "df2 = pd.concat([df2, pd.get_dummies(df[\"job\"],prefix='job',drop_first=True)], axis=1)\n",
    "df2 = pd.concat([df2, pd.get_dummies(df[\"housing\"],prefix='housing',drop_first=True)], axis=1)\n",
    "df2 = pd.concat([df2, pd.get_dummies(df[\"loan\"],prefix='loan',drop_first=True)], axis=1)\n",
    "df2 = pd.concat([df2, pd.get_dummies(df[\"contact\"],prefix='contact',drop_first=True)], axis=1)\n",
    "df2 = pd.concat([df2, pd.get_dummies(df[\"month\"],prefix='month',drop_first=True)], axis=1)\n",
    "df2 = pd.concat([df2, pd.get_dummies(df[\"day_of_week\"],prefix='day_of_week',drop_first=True)], axis=1)\n",
    "df2 = pd.concat([df2, pd.get_dummies(df[\"poutcome\"],prefix='poutcome',drop_first=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el nuevo número de variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifiquemos que ninguna variable tenga desviación estándar cero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import preprocessing\n",
    "#le = preprocessing.LabelEncoder()\n",
    "\n",
    "#X = df2.values\n",
    "#le.fit(df['y'].unique())\n",
    "#Y = le.transform(df['y'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realice la partición de los datos entre Entrenamiento y Test. Recuerde que Test es el subconjunto que dejará pára medir el desempeño del sistema después del entrenamiento y de la selección de los hiperparámetros. \n",
    "\n",
    "Teniendo en cuenta la distribución de clases, seleccione correctamente la estrategia de particionamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio de código\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Complete el código\n",
    "X_train, X_test, y_train, y_test = train_test_split(df2, df['y'], test_size=0.2, stratify=..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalice los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio de código\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = \n",
    "X_train_n = \n",
    "X_test_n = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Selección de hiper-parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo que vamos a usar para este ejercicio es KNeighborsClassifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina la metodología de validación apropiada teniendo en cuenta la distribución de clases del problema e instancie un objeto iterador de acuerdo con el método escogido para ser usado por el método GridSearch. \n",
    "\n",
    "- Si la metodología es de tipo ShuffleSplit defina un tamaño de test = 0.2\n",
    "- Si la metodología es de tipo KFold defina un número de folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio de código\n",
    "from sklearn.model_selection import ...\n",
    "st = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a usar el método GridSearch para que realice la búsqueda de los mejores hiperparámetros del modelo. Los hiperparámetros a ajustar son el número de vecinos y el tipo de medida de distancia.\n",
    "\n",
    "El método GridSearch contiene el parámetro **'scoring'** en el cual se define la medida de desempeño que será usada para seleccionar los mejores hiperparámetros. En este caso se van a hacer dos pruebas una usando la métrica 'accuracy' y la segunda usando la métrica 'balanced_accuracy'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "np.random.seed(4)\n",
    "\n",
    "#Número de vecinos a evaluar\n",
    "k=[1,3,5,7,9,11]\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors':k, 'metric':['euclidean','manhattan','chebyshev']}\n",
    "\n",
    "clf1 = GridSearchCV(estimator=knn, param_grid = parameters, cv=st, scoring='accuracy',return_train_score=True)\n",
    "clf1.fit(X_train_n, y_train)\n",
    "\n",
    "clf2 = GridSearchCV(estimator=knn, param_grid = parameters, cv=st, scoring='balanced_accuracy',return_train_score=True)\n",
    "clf2.fit(X_train_n, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál de las dos búsquedas anteriores entrega mejor score de validación? ¿Cuál es el mejor conjunto de hiperparámetros encontrado en cada caso? Escriba el código necesario para averiguralo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio de código\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown  ¿Cómo explica la diferencia en le número de vecinos óptimo en cada una de las dos búsquedas?\n",
    "respuesta_1 = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es el score de entrenamiento para la mejor combinación de parámetros en cada una de las búsquedas? Escriba el código necesario para averiguralo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio de código\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a medir el desempeño en el conjunto de test, del mejor modelo para cada una de las búsquedas. Ejecute la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "print('Balanced Accuracy test búsqueda 1 = '+str(balanced_accuracy_score(y_test,clf1.predict(X_test_n))))\n",
    "print('Balanced Accuracy test búsqueda 2 = '+str(balanced_accuracy_score(y_test,clf2.predict(X_test_n))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown  ¿Hay diferencia entre el score de training y el score de validación? ¿Cómo se explica la diferencia?\n",
    "respuesta_2 = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafique la matriz de confusión normalizada del mejor modelo para cada una de las búsquedas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio de código\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "disp = ...\n",
    "disp.ax_.set_title('CM_Búsqueda 1')\n",
    "\n",
    "disp = ...\n",
    "disp.ax_.set_title('CM_Búsqueda 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Compensación del desbalance\n",
    "\n",
    "Una forma de compensar el desbalance es usar un modelo que pueda darle un peso diferente al error que se comete con cada muestra, de acuerdo con la clase. Vamos a repetir el análisis usando en este caso un FandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso los hiperparámetros a seleccionar son el número de árboles y la profundida de los árboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=[10,20,30,40,50,60,100]\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "parameters = {'n_estimators':B, 'max_depth':[4,6,8,10,12,14]}\n",
    "\n",
    "clf3 = GridSearchCV(estimator=rf, param_grid = parameters, cv=st, scoring='balanced_accuracy',return_train_score=True)\n",
    "clf3.fit(X_train_n, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el desemepeño del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Balanced Accuracy test búsqueda 3 = '+str(balanced_accuracy_score(y_test,clf3.predict(X_test_n))))\n",
    "#Complete el código para graficar la matriz de confusión\n",
    "disp = ...\n",
    "disp.ax_.set_title('CM_Búsqueda 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repita el proceso anterior pero ahora introduzca la opción: **class_weight='balanced_subsample'** en la definición del modelo RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio de código\n",
    "\n",
    "rf = \n",
    "clf4 = \n",
    "clf4.fit(X_train_n, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el desemepeño del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Balanced Accuracy test búsqueda 3 = '+str(balanced_accuracy_score(y_test,clf4.predict(X_test_n))))\n",
    "#Complete el código para graficar la matriz de confusión\n",
    "\n",
    "disp = ...\n",
    "disp.ax_.set_title('CM_Búsqueda 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy test búsqueda 3 = '+str(accuracy_score(y_test,clf4.predict(X_test_n))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown  ¿Hay diferencia significativa entre el acc y el bacc en el conjunto de test para el último modelo entrenado? Justifique su respuesta.\n",
    "respuesta_3 = \"\" #@param {type:\"string\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
