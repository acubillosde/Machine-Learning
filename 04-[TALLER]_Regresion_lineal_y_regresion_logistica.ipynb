{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DyhyA0EkYySm"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/UDEA-Esp-Analitica-y-Ciencia-de-Datos/EACD-04-MACHINE-LEARNING-1/blob/master/04-%5BTALLER%5D_Regresion_lineal_y_regresion_logistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\n",
    "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras alamancenar tu progreso**\n",
    "\n",
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-cache -O init.py -q https://raw.githubusercontent.com/UDEA-Esp-Analitica-y-Ciencia-de-Datos/EACD-04-MACHINE-LEARNING-1/master/init.py\n",
    "import init; init.init(force_download=False); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuración del laboratorio\n",
    "# Ejecuta esta celda!\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller - Parte 1\n",
    "\n",
    "**Regresión polinomial múltiple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.lib.general import configure_lab1_p1\n",
    "configure_lab1_p1()\n",
    "from local.lib.lab1 import *\n",
    "GRADER_LAB_1_P1, db, x, y = part_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.1: Contextualización del problema\n",
    "\n",
    "El problema de regresión que abordaremos consiste en predecir el valor de la humedad absoluta en el aire, a partir de varias variables sensadas en el aire (Para más información sobre la base de datos y la contextualización del problema, consulte: [link](http://archive.ics.uci.edu/ml/datasets/air+quality))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tienes ya cargadas las siguientes variables:\n",
    "print(\"conjunto de datos\", x)\n",
    "print(\"variable a predecir\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio de Codigo\n",
    "def num_muestras_carac(X):\n",
    "    \"\"\"Esta funcion es encargada retornar el numero de muestras\n",
    "        y caracteristicas del conjunto de datos X\n",
    "\n",
    "        X: matriz numpy\n",
    "        retorna:\n",
    "            numero de muestras (int/float)\n",
    "            numero de caracteristicas (int/float)\n",
    "    \"\"\"\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## la funcion que prueba tu implementacion\n",
    "GRADER_LAB_1_P1.run_test(\"ejercicio1.1\", num_muestras_carac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown  ¿que tipo de problema vamos a resolver?\n",
    "respuesta_1 = \" \" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.2\n",
    "\n",
    "Analice los siguientes métodos de la teoría  de modelos de  *regresión polinomial múltiple*:\n",
    "\n",
    "1. Error cuadrático medio (<font color='blue'>ECM</font>), \n",
    "2. Modelo de regresión múltiple (<font color='blue'>regression</font>)\n",
    "4. Gradiente descendente.\n",
    "\n",
    "La siguiente celda contiene la implementación del ECM y de la regression. Comprenda su funcionamiento y ejecute la celda para definir las funciones y poder usarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECM(Y,Y_est):\n",
    "    \"\"\"funcion para calcular el error cuadratico medio\n",
    "    Y_est: debe contener los valores predichos por el modelo evaluar\n",
    "    Y: debe contener los valores reales\n",
    "    retorna: error cuadratico medio\n",
    "    \"\"\"\n",
    "    N = np.size(Y)\n",
    "    ecm = np.sum((Y_est.reshape(N,1) - Y.reshape(N,1))**2)/(N)\n",
    "    return ecm \n",
    "\n",
    "def regression(X, W):\n",
    "    \"\"\"calcula la regresión multiple\n",
    "    X: los valores que corresponden a las caractersiticas\n",
    "    W: son los pesos usadados para realizar la regresión\n",
    "    retorna: valor estimado\n",
    "    \"\"\"    \n",
    "    Yest = np.dot(X,W)    #con np.dot se realiza el producto matricial. Aquí X es dim [Nxd] y W es dim [dx1]\n",
    "    return Yest           #Esta variable contiene la salida de f(X,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual manera, debemos extender nuestro conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extendemos la matriz de X para incluir el término independiente\n",
    "def MatrizExtendida(X):\n",
    "    # par obtener el numero muestras y caractersiticas\n",
    "    muestras,carac = num_muestras_carac(X)\n",
    "    unos = np.array([np.ones(muestras)])\n",
    "    x_ext = np.concatenate((unos.T, X), axis=1)\n",
    "    x_ext = x_ext.reshape(muestras, carac+1)\n",
    "    return x_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ejercicio de codigo\n",
    "def gradiente_descendente(X, Y, eta, iteraciones):\n",
    "    \"\"\"Gradiente descendente para regresión lineal múltiple\n",
    "    X: Matriz de datos extendida\n",
    "    Y: vector con los valores a predecir\n",
    "    W: Vector de parámetros del modelo\n",
    "    eta: Taza de aprendizaje\n",
    "\n",
    "    retorna: W el valor de de los parametros de regresión polinomica\n",
    "    \"\"\"\n",
    "     \n",
    "    #Extendemos la matriz\n",
    "    X= MatrizExtendida(X)\n",
    "        \n",
    "    #Inicializamos el vector de parámetros con ceros y suamos la función\n",
    "    # para saber el numero de muestras y caractersiticas\n",
    "    \n",
    "    N, caracterisitcas = num_muestras_carac(X)\n",
    "    Y = Y.reshape(-1,1)\n",
    "    W = np.zeros((1,caracterisitcas))\n",
    "    W = W.reshape(np.size(W), 1)    \n",
    "\n",
    "    for iter in range(iteraciones):\n",
    "        ## Aca debes completar la funcion! recuerda que solo debes usar numpy (np.funcion_a_usar)\n",
    "        ## para actualizar los pesos W.\n",
    "        ## Pista: consulta que efecto tienen los parametros keepdims y axis en np.sum()\n",
    "\n",
    "        W = \n",
    "      \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## la funcion que prueba tu implementacion\n",
    "GRADER_LAB_1_P1.run_test(\"ejercicio1.2\", gradiente_descendente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.3: Entrenamiento\n",
    "\n",
    "Con la función implementada vamos a entrenar un modelo y calcular su error de entrenamiento. Antes de realizar esto, debemos separar nuestro conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto para lograr reproductibilidad\n",
    "# de nuestro modelo\n",
    "y = y.reshape(np.size(y), 1)\n",
    "random.seed(1)\n",
    "# usamos nuestra funcion para obtener el numero de muestras\n",
    "N, _ = num_muestras_carac(x)\n",
    "ind=np.random.permutation(N)\n",
    "Xtrain = x[ind[0:int(math.ceil(0.7*N))],:]\n",
    "Xtest = x[ind[int(math.ceil(0.7*N)):N],:]\n",
    "Ytrain = y[ind[0:int(math.ceil(0.7*N))]]\n",
    "Ytest = y[ind[int(math.ceil(0.7*N)):N]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora entrena ejecutando la siguiente linea de codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = gradiente_descendente(Xtrain, Ytrain, eta = 0.0001, iteraciones=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a evaluar nuestro modelo calculando el error cuadrático medio. Para ello vamos crear a una función. Recuerda usar las funciones definidas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ejercicio de Código\n",
    "def evaluar_modelo (W, X_to_test, Y_True):\n",
    "    \"\"\" funcion que evalua un modelo de regresión usando el error cuadratico medio\n",
    "\n",
    "    W: es un matriz con los parametros del modelo entrenados\n",
    "    X_to_test: conjunto de datos para usar en el evaluamiento del modelo\n",
    "    Y_True: valores reales para usar en el evaluamiento del modelo\n",
    "\n",
    "    retorna: el error cuadratico medio\n",
    "    \"\"\"\n",
    "       \n",
    "    ## Comienza a completar tu codigo. recuerda usar la funciones ya definidas\n",
    "    \n",
    "    Y_est = \n",
    "    error = \n",
    "    return(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## la funcion que prueba tu implementacion\n",
    "GRADER_LAB_1_P1.run_test(\"ejercicio1.3\", evaluar_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y ahora usala para calcular el error, para evaluar el modelo\n",
    "error_train = evaluar_modelo(W, X_to_test = MatrizExtendida(Xtrain),  Y_True = Ytrain)\n",
    "print(\"error en entrenamiento del modelo\", error_train)\n",
    "error_test = evaluar_modelo(W, X_to_test = MatrizExtendida(Xtest),  Y_True = Ytest)\n",
    "print(\"error en la evaluación del modelo\", error_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.4: \n",
    "\n",
    "Ahora aumentemos el grado del polinomio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potencia de polinomio\n",
    "def potenciaPolinomio(X,grado):\n",
    "    \"\"\"calcula la potencia del polinomio\n",
    "    X: los valores que corresponden a las caractersiticas\n",
    "    grado: esl grado para realizar la potencia al polinomio\n",
    "    retorna: el valor de X despues elevarlo al grado del polinimoo indicado\n",
    "    \"\"\"\n",
    "    X2 = X.copy()\n",
    "    \n",
    "    if grado != 1:\n",
    "        for i in range(2,grado+1):\n",
    "            Xadd = X**i\n",
    "            X2 = np.concatenate((X2, Xadd), axis=1)\n",
    "    \n",
    "    return X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ejercicio de codigo\n",
    "def gradiente_descendente_poly (X, Y, eta, iteraciones, grado):\n",
    "    \"\"\"Gradiente descendente para regresión lineal múltiple\n",
    "    X: Matriz de datos extendida\n",
    "    Y: vector con los valores a predecir\n",
    "    W: Vector de parámetros del modelo\n",
    "    eta: Taza de aprendizaje\n",
    "    iteraciones: numero de iteraciones maximo para el gradiente\n",
    "    grado: el valor del polinomio a usar\n",
    "    retorna: W el valor de de los parametros de regresión polinomica\n",
    "    \"\"\"\n",
    "    X2 = potenciaPolinomio(X,grado)\n",
    "    \n",
    "    ## completa el codigo\n",
    "    W = \n",
    "    return (W)\n",
    "\n",
    "def evaluar_modelo_poly (W, X_to_test, Y_True, grado):\n",
    "    \"\"\" funcion que evalua un modelo de regresión usando el error cuadratico medio\n",
    "\n",
    "    W: es un matriz con los parametros del modelo entrenados\n",
    "    X_to_test: conjunto de datos para usar en el evaluamiento del modelo\n",
    "    Y_True: valores reales para usar en el evaluamiento del modelo\n",
    "    grado: grado del polinimio a usar\n",
    "\n",
    "    retorna: el error cuadratico medio\n",
    "    \"\"\"\n",
    "    ## Comienza a completar tu codigo. recuerda usar la funciones ya definidas\n",
    "    X2 = \n",
    "    error = \n",
    "    return(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## la funcion que prueba tu implementacion\n",
    "GRADER_LAB_1_P1.run_test(\"ejercicio1.4\", gradiente_descendente_poly)\n",
    "GRADER_LAB_1_P1.run_test(\"ejercicio1.5\", evaluar_modelo_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos\n",
    "W = gradiente_descendente_poly(Xtrain, Ytrain, eta = 0.0001, iteraciones=2, grado = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluamos\n",
    "error_test = evaluar_modelo_poly(W, X_to_test = Xtest,  Y_True = Ytest, grado = 2)\n",
    "print(\"error en la evaluación del modelo\", error_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.5: \n",
    "\n",
    "Vamos a ejecutar el proceso para diferentes valores de los hiperparámetros tanto del modelo como del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ejercicio de codigo\n",
    "def experimentar (Xtrain, Xtest, Ytrain, Ytest, tasas, grados):\n",
    "    \"\"\" funcion para realizar experimentos.\n",
    "    Xtrain: conjunto de datos\n",
    "    Xtest:\n",
    "    Ytrain:\n",
    "    Ytest:\n",
    "    tasas: Es una lista con los valores númericos de tasas de aprendizaje \n",
    "        para realizar los experimentos\n",
    "    grados: Es una lista con los valores númericos de grados \n",
    "        para realizar los experimentos\n",
    "    retorna: un dataframe con el resultados de los experimentos\n",
    "    \"\"\"\n",
    "    numero_iter = 5\n",
    "\n",
    "    resultados = pd.DataFrame()\n",
    "    idx = 0 # indice\n",
    "    for eta in tasas:\n",
    "        for grado in grados:\n",
    "\n",
    "            W = gradiente_descendente_poly (Xtrain, Ytrain, eta, numero_iter, grado)\n",
    "            error = evaluar_modelo_poly (W, Xtest, Ytest, grado)\n",
    "        \n",
    "            resultados.loc[idx,'grado'] = grado\n",
    "            resultados.loc[idx,'tasa de aprendizaje'] = eta\n",
    "            resultados.loc[idx,'ecm'] = error\n",
    "            idx = idx+1\n",
    "\n",
    "    return (resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## la funcion que prueba tu implementacion\n",
    "GRADER_LAB_1_P1.run_test(\"ejercicio1.6\", experimentar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ahora usa para verlos los resultados\n",
    "tasas_aprendizaje = [1e-6, 1e-5, 1e-3, 1e-2]\n",
    "grados_polinomio = [1,2,3]\n",
    "resultados_ex1 = experimentar(Xtrain, Xtest, Ytrain, Ytest, tasas_aprendizaje, grados_polinomio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para ver los resultados\n",
    "resultados_ex1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si has implementado todo correctamente, parecieria que nuestros entrenamientos no esta logrando buenos resultados (hasta puede haber errores infinitos! o no determinados!). \n",
    "\n",
    "Ahora normalicemos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizamos los datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def normalizar(Xtrain):\n",
    "    \"\"\" función que se usa para normalizar los datos con\n",
    "    un metodo especifico\n",
    "    Xtrain: matriz de datos entrenamiento a normalizar\n",
    "    Xtest: matriz de datos evaluación a normalizar\n",
    "    retorna: matrices normalizadas\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler().fit(Xtrain)\n",
    "    Xtrain_n = scaler.transform(Xtrain)\n",
    "\n",
    "    return Xtrain_n, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1., -1.],\n",
       "        [ 1.,  1.]]), StandardScaler())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizar(np.array([[1,2],[2,4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nuevamente los funciones gradiente_descendente_poly y evaluar_modelo_poly para tener en cuenta la normalización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ejercicio de codigo\n",
    "def gradiente_descendente_poly (X, Y, eta, iteraciones, grado):\n",
    "    \"\"\"Gradiente descendente para regresión lineal múltiple\n",
    "    X: Matriz de datos extendida\n",
    "    Y: vector con los valores a predecir\n",
    "    W: Vector de parámetros del modelo\n",
    "    eta: Taza de aprendizaje\n",
    "    iteraciones: numero de iteraciones maximo para el gradiente\n",
    "    grado: el valor del polinomio a usar\n",
    "    retorna: W el valor de de los parametros de regresión polinomica y el scaler para normalizar muestras de test\n",
    "    \"\"\"\n",
    "    X2 = potenciaPolinomio(X,grado)\n",
    "    \n",
    "    ## completa el codigo\n",
    "    \n",
    "    X2_n,scaler = \n",
    "    \n",
    "    W = \n",
    "    return W,scaler\n",
    "\n",
    "def evaluar_modelo_poly (W, X_to_test, Y_True, grado, scaler):\n",
    "    \"\"\" funcion que evalua un modelo de regresión usando el error cuadratico medio\n",
    "\n",
    "    W: es un matriz con los parametros del modelo entrenados\n",
    "    X_to_test: conjunto de datos para usar en el evaluamiento del modelo\n",
    "    Y_True: valores reales para usar en el evaluamiento del modelo\n",
    "    grado: grado del polinimio a usar\n",
    "\n",
    "    retorna: el error cuadratico medio\n",
    "    \"\"\"\n",
    "    ## Comienza a completar tu codigo. recuerda usar la funciones ya definidas\n",
    "    X2 = \n",
    "    \n",
    "    error = evaluar_modelo (W, MatrizExtendida(X2), Y_True)\n",
    "    return(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vuelve a realizar los mismos experimentos pero esta vez usa los valores de salida de la función anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ejercicio de codigo\n",
    "def experimentar (Xtrain, Xtest, Ytrain, Ytest, tasas, grados):\n",
    "    \"\"\" funcion para realizar experimentos.\n",
    "    Xtrain: conjunto de datos\n",
    "    Xtest:\n",
    "    Ytrain:\n",
    "    Ytest:\n",
    "    tasas: Es una lista con los valores númericos de tasas de aprendizaje \n",
    "        para realizar los experimentos\n",
    "    grados: Es una lista con los valores númericos de grados \n",
    "        para realizar los experimentos\n",
    "    retorna: un dataframe con el resultados de los experimentos\n",
    "    \"\"\"\n",
    "    numero_iter = 5\n",
    "\n",
    "    resultados = pd.DataFrame()\n",
    "    idx = 0 # indice\n",
    "    for eta in tasas:\n",
    "        for grado in grados:\n",
    "\n",
    "            W,scaler = \n",
    "            error = \n",
    "        \n",
    "            resultados.loc[idx,'grado'] = grado\n",
    "            resultados.loc[idx,'tasa de aprendizaje'] = eta\n",
    "            resultados.loc[idx,'ecm'] = error\n",
    "            idx = idx+1\n",
    "\n",
    "    return (resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_ex2 = experimentar(Xtrain, Xtest, Ytrain, Ytest, tasas_aprendizaje, grados_polinomio)\n",
    "#para ver los resultados\n",
    "resultados_ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown  ¿Qué proceso hace la normalización sobre los datos? Consulte por qué es necesaria la normalización en el modelo de regresión y cuáles son los tipos de normalización más comunes. ¿Cuál de ellos se aplicó en el laboratorio?\n",
    "respuesta_2 = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafiquemos algunos resultados\n",
    "import seaborn as sns\n",
    "s = sns.catplot(data = resultados_ex2, x = 'tasa de aprendizaje',\n",
    "            y = 'ecm',hue ='grado', kind = 'bar', )\n",
    "s.set(yscale=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.6: \n",
    "\n",
    "Veamos ahora el efecto del número de iteraciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ejercicio de codigo\n",
    "def experimentar_2 (Xtrain, Xtest, Ytrain, Ytest, iteraciones, grados):\n",
    "    \"\"\" funcion para realizar experimentos.\n",
    "    Xtrain: conjunto de datos\n",
    "    Xtest:\n",
    "    Ytrain:\n",
    "    Ytest:\n",
    "    tasas: Es una lista con los valores númericos de tasas de aprendizaje \n",
    "        para realizar los experimentos\n",
    "    rangos: Es una lista con los valores númericos de grados \n",
    "        para realizar los experimentos\n",
    "    retorna: un dataframe con el resultados de los experimentos\n",
    "    \"\"\"\n",
    "    eta = 1e-2\n",
    "    resultados = pd.DataFrame()\n",
    "    idx = 0 # indice\n",
    "    for itera in iteraciones:\n",
    "        for grado in grados:\n",
    "            W,scaler = \n",
    "            error = \n",
    "        \n",
    "            resultados.loc[idx,'iteraciones'] = itera\n",
    "            resultados.loc[idx,'grado'] = grado\n",
    "            resultados.loc[idx,'ecm'] = error\n",
    "            idx = idx+1\n",
    "    return (resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## la funcion que prueba tu implementacion\n",
    "GRADER_LAB_1_P1.run_test(\"ejercicio1.7\", experimentar_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = [1,5,10,20,50, 100,200]\n",
    "grados_polinomio = [1,2,3]\n",
    "# usamos la funcion para evaliar los resultados\n",
    "resultados_ex3 = experimentar_2(Xtrain, Xtest, Ytrain, Ytest, num_iters, grados_polinomio )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_ex3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecuta esta linea de codigo para ver graficamente tus resultados\n",
    "import seaborn as sns\n",
    "sns.relplot(data = resultados_ex3, x = 'iteraciones',y = 'ecm',col ='grado', kind = 'line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRADER_LAB_1_P1.check_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Integrantes\n",
    "codigo_integrante_1 ='' #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Esta linea de codigo es de uso exclusivo del los profesores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRADER_LAB_1_P1.grade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0kgAjuBYySp"
   },
   "source": [
    "## Taller - Parte 2\n",
    "\n",
    "**Regresión logística**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lab configuration started\n",
      "installing libraries\n",
      "downloading files\n",
      "lab configured\n",
      "cargando librerias y variables al ambiente\n"
     ]
    }
   ],
   "source": [
    "from local.lib.general import configure_lab1_p2\n",
    "configure_lab1_p2()\n",
    "from local.lib.lab1 import *\n",
    "GRADER, x, y = part_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0gwFeCnYySq"
   },
   "source": [
    "## Ejercicio 2.1: Contextualización del problema\n",
    "\n",
    "En esta sesión de laboratorio, vamos a resolver un problema de clasificación. Los variables que vamos a usar ya se encuentran cargadas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-jBTrc4YySq",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conjunto de datos, muestra \n",
      " [[ 3.92606402 -6.83699086]\n",
      " [ 7.43382787 -3.7485991 ]\n",
      " [ 6.20553473  4.77182668]\n",
      " [ 6.77983287 -3.07765299]\n",
      " [-5.92614125 -4.87588843]\n",
      " [ 7.49283136  3.9516693 ]\n",
      " [-1.65572633  6.86081477]\n",
      " [-8.14881988 -1.85421149]\n",
      " [ 8.12616581 -1.66701921]\n",
      " [ 9.73411311 -1.63724335]]\n",
      "\n",
      " muestra de etiquetas a predecir \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# tienes ya cargadas las siguientes variables:\n",
    "print(\"conjunto de datos, muestra \\n\",x[range(10), :] )\n",
    "print(\"\")\n",
    "print(\" muestra de etiquetas a predecir \\n\", y[range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5lvqd4i0YySs"
   },
   "outputs": [],
   "source": [
    "#Ejercicio de Codigo\n",
    "def clases_muestras_carac(X, Y):\n",
    "    \"\"\"Esta funcion es encargada retornar el numero clases, muestras \n",
    "        y caracteristicas del conjunto de datos X y Y\n",
    "\n",
    "        X: matriz numpy con el conjunto de datos para entrenamiento\n",
    "        Y: matriz numpy con el conjunto de etiquetas\n",
    "        retorna:\n",
    "            numero de muestras (int/float)\n",
    "            numero de caracteristicas (int/float)\n",
    "            numero de clases (int/float)\n",
    "    \"\"\"\n",
    "    ##Pista: es de utilidad el metodo np.unique ?\n",
    "    N,nf = \n",
    "    clases = \n",
    "    \n",
    "    return (N,nf,clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBS6kWmkYySu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## la funcion que prueba tu implementacion\n",
    "GRADER.run_test(\"ejercicio2.1\", clases_muestras_carac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I8zabv6IYySw"
   },
   "source": [
    "En los problemas de clasificación, que lo permiten, es de utilidad visualizar los datos. De esta manera uno puede determinar que modelos o algortimos pueden tener mejor rendimiento. En la siguiente función, debera, graficar los datos usando la función [scatter](https://matplotlib.org/gallery/shapes_and_collections/scatter.html) de matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xjiRibSVYySw"
   },
   "outputs": [],
   "source": [
    "def scatter_plot(X, Y):\n",
    "    \"\"\"Esta funcion es encargada de graficar usando un scatter plot\n",
    "       un problema de clasificacion.\n",
    "\n",
    "        X: matriz numpy con el conjunto de datos para entrenamiento.\n",
    "           esta debera ser usada para los ejes del grafico. puede asumir\n",
    "           que solo va a tener dos columnas\n",
    "        Y: matriz numpy con el conjunto de etiquetas. Debera ser usada\n",
    "           para mostrar en diferentes colores, las etiquetas de cada una\n",
    "           de las muestras\n",
    "        retorna:\n",
    "            grafica matplotlib\n",
    "    \"\"\"\n",
    "    ## puedes accerder con plt al funcion adecuacada\n",
    "    ## Pista: recuerda como indexar matrices\n",
    "    ## Pista: recuerda el uso de np.ravel\n",
    "    # para mostrar el grafico\n",
    "    figure = plt.gcf()\n",
    "    Y = Y.flatten()\n",
    "    clases = np.unique(Y)\n",
    "    for i in clases:\n",
    "        plt.scatter(X[Y==i,0],X[Y==i,1],label='Clase_'+str(i))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "   \n",
    "    #return (figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter_plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "sq2e7UwwYyS2"
   },
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown  ¿El problema es linealmente separable? justifique su respuesta \n",
    "respuesta_3 = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYCpYnI0YyS4"
   },
   "source": [
    "## Ejercicio 2.2: entrenamiento\n",
    "\n",
    "En esta sección se va a realizar un procedimiento análogo a la parte 1, pero con el modelo de *regresión logística* que sirve para resolver problemas de clasificación (en principio biclase).\n",
    "\n",
    "Analice los siguientes métodos a la luz de la teoría vista para el modelo de regresión logística: \n",
    "\n",
    "1. función de activación (<font color='blue'>sigmoidal</font>),\n",
    "2.  modelo de regresión logística (<font color='blue'>logistic_regression</font>), \n",
    "3. potencia del polinomio \n",
    "4.  el cálculo del error en clasificación (<font color='blue'>error_logistic</font>)\n",
    "5. el gradiente descendente. \n",
    "\n",
    "Luego de recordar estos conceptos. Complete la función sigmoidal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WAQAglStYyS4"
   },
   "outputs": [],
   "source": [
    "#Ejercicio de Código\n",
    "def sigmoidal(z):\n",
    "    \"\"\"Función de activación Sigmoidal\n",
    "\n",
    "    z: es la varible a la que se le va aplicar el sigmoide.\n",
    "       es un array numpy de uan sola dimension\n",
    "    retorna: el valor del sigmiode\n",
    "\n",
    "    \"\"\"\n",
    "    #Complete la siguiente línea con el código para calcular la salida de la función sigmoidal\n",
    "    s = \n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hiui_rfgYyS6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## la funcion que prueba tu implementacion\n",
    "GRADER.run_test(\"ejercicio2.3\", sigmoidal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6t8dJoLfYyS7"
   },
   "source": [
    "El la siguiente celda se sugiere la implementación, de los siguientes conceptos:\n",
    "\n",
    "1. modelo de regresión logística (<font color='blue'>logistic_regression</font>), \n",
    "2. potencia del polinomio \n",
    "3.  el cálculo del error en clasificación (<font color='blue'>error_logistic</font>)\n",
    "\n",
    "comprenda que hacen estas funciones y ejecute la celda para cargar las funciones, para porder usarlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-yCVeVQYyS8"
   },
   "outputs": [],
   "source": [
    "def logistic_regression(X, W):\n",
    "    \"\"\"calcula la regresión logistica\n",
    "    X: los valores que corresponden a las caractersiticas\n",
    "    W: son los pesos usadados para realizar la regresión\n",
    "    retorna: valor estimado por la regresion\n",
    "    \"\"\"\n",
    "    #Con np.dot se realiza el producto matricial. Aquí X (extendida) tiene dim [Nxd] y W es dim [dx1]\n",
    "    Yest = np.dot(X,W)\n",
    "    Y_lest = sigmoidal(Yest)\n",
    "        \n",
    "    return Y_lest    \n",
    "\n",
    "def error_logistic(Y_lest, Y):\n",
    "    \"\"\"calculo del error logistico\n",
    "       Si es diferente el Y_estimado con el Y_real cuenta como un error\n",
    "       Y_lest: numpy array con los valores de etiquetas estimadas\n",
    "       Y:  numpy array  valor con los valores reales de las etiquetas\n",
    "       retorna: error de clasificación -- numpy array\n",
    "    \"\"\"\n",
    "    error = 0\n",
    "    for ye, y in zip(Y_lest, Y):\n",
    "        if ye != y:\n",
    "            error += 1\n",
    "    \n",
    "    error = error/np.size(Y)\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qGIrWUZoYyS-"
   },
   "outputs": [],
   "source": [
    "#Aca llamamos la funcion creada anteriormente\n",
    "# para obtener el numero muestras y caractersiticas\n",
    "muestras,caracterisitcas,num_clases = clases_muestras_carac(x, y)\n",
    "y = y.reshape(np.size(y), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6rbFHQxYyS_"
   },
   "source": [
    "Recordando lo aprendido anteriormente, dividimos nuestro cojunto de datos y normalizamos. Ahora usamos una aproximación de un poco más alto nivel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8F2NBNVwYyTA"
   },
   "outputs": [],
   "source": [
    "#Dejamos algunas muestras para el proceso de entrenamiento y otras para evaluar qué tan bueno fue el aprendizaje del modelo\n",
    "from sklearn.model_selection import train_test_split\n",
    "random.seed(1)\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(x, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NX9X-ocwYyTC"
   },
   "source": [
    "Ahora vamos a completar el código de la regla de actualización de los parámetros del algoritmo de <font color='blue'>gradiente_descedente</font>. Adicionalmente, dentro de nuestra función, **vamos incluir una transformación polinómica**.\n",
    "\n",
    "Nota: Para el problema de clasificación tenga presente que si ya implementó la regla de actualización de parámetros para el modelo de regresión polinomial múltiple, este punto es trivial, puesto que sólo tiene que incluir la función sigmoidal tal como lo vimos en la teoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zLtR3kdKYyTC"
   },
   "outputs": [],
   "source": [
    "#ejercicio de codigo\n",
    "def gradiente_descendente_logistic_poly(X,Y,grado,eta, iteraciones):\n",
    "    \"\"\"Gradiente descendente para regresión lineal múltiple\n",
    "    X: Matriz de datos extendida\n",
    "    Y: vector con los valores a predecir\n",
    "    W: Vector de parámetros del modelo\n",
    "    eta: Taza de aprendizaje\n",
    "    grado: grado para usar en la transformacion polinomica\n",
    "    iteraciones: numero de iteraciones maxima\n",
    "\n",
    "    retorna: W el valor de de los parametros de regresión polinomica\n",
    "    \"\"\"\n",
    "    Y = Y.reshape(-1,1)\n",
    "    \n",
    "    #Extendemos las variables para usar polinomios de grado superior\n",
    "    X2 = potenciaPolinomio(X,grado)\n",
    "    \n",
    "    #Normalizamos\n",
    "    X2_n,scaler = \n",
    "    \n",
    "    #Extendemos la matriz\n",
    "    X2_n= \n",
    "    \n",
    "    #Tomamos el número de variables del problema leugo de la transformacion\n",
    "    d = np.size(X2_n,1)\n",
    "    #Tomamos el número de muestras de la base de datos\n",
    "    N = np.size(X2_n,0)   \n",
    "    #Inicializamos el vector de parámetros\n",
    "    W = np.zeros(d)\n",
    "    W = W.reshape(np.size(W),1)\n",
    "   \n",
    "   \n",
    "    for iter in range(iteraciones):\n",
    "       \n",
    "        #Aquí debe completar el código con la regla de actualización de los parámetros W para regresión\n",
    "        #logística. Tenga en cuenta los nombres de las variables ya creadas\n",
    "        Y_estimado = logistic_regression(X2_n,W)\n",
    "\n",
    "        W = \n",
    "\n",
    "\n",
    "    #Error en clasificación  \n",
    "    Y_estimado = np.round(logistic_regression(X2_n,W))\n",
    "    error_clasificacion = error_logistic(Y_estimado,Y)\n",
    "    print(\"error despues de finalizar la iteraciones\", error_clasificacion)\n",
    "    return W, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhrk1KyYYyTE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## la funcion que prueba tu implementacion\n",
    "GRADER.run_test(\"ejercicio2.4\", gradiente_descendente_logistic_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pjpTN71aYyTF"
   },
   "source": [
    "Finalmente se sugiere la siguiente funcion para evaluar el error del modelo. Entienda su funcionamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhbCT0H0YyTG"
   },
   "outputs": [],
   "source": [
    "def evaluar_modelo (W, X_to_test, Y_True, grado,scaler):\n",
    "    \"\"\" funcion que evalua un modelo de regresión usando el error cuadratico medio\n",
    "\n",
    "    W: es un matriz con los parametros del modelo entrenados\n",
    "    X_to_test: conjunto de datos para usar en el evaluamiento del modelo\n",
    "    Y_True: valores reales para usar en el evaluamiento del modelo\n",
    "    grado: valor del polinomio a usar\n",
    "\n",
    "    retorna: el de clasificación.\n",
    "    \"\"\"\n",
    "    X2 = potenciaPolinomio(X_to_test,grado)\n",
    "    X2 = scaler.transform(X2)\n",
    "    \n",
    "    Y_estimado = np.round(logistic_regression(MatrizExtendida(X2),W))\n",
    "    error_clasificacion = error_logistic(Y_estimado,Y_True)\n",
    "    return(error_clasificacion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EhaV3W7IYyTH"
   },
   "source": [
    "## Ejercicio 2.3: Experimentar\n",
    "\n",
    "Con la función implementada vamos a entrenar un modelo y calcular su error de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wwIVbTDYyTI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "w, scaler = gradiente_descendente_logistic_poly(Xtrain,Ytrain,1,0.0001, 1000)\n",
    "error_test = evaluar_modelo(w, Xtest, Ytest, 1, scaler)\n",
    "print(\"error en el conjunto de pruebas\", error_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bH00WKqYYyTJ"
   },
   "source": [
    "En nuestro primer experimento vamos a evaluar el rendimiento del modelo usando varias tasas de aprendizaje y grados de polinimios. Vamos a dejar por ahora un numero de iteraciones fijas = 50. Para ello completa la siguiente función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2L4aHWL4YyTK"
   },
   "outputs": [],
   "source": [
    "## ejercicio de codigo\n",
    "def experimentar (Xtrain, Xtest, Ytrain, Ytest, tasas, grados):\n",
    "    \"\"\" funcion para realizar experimentos.\n",
    "    Xtrain: conjunto de datos\n",
    "    Xtest:\n",
    "    Ytrain:\n",
    "    Ytest:\n",
    "    tasas: Es una lista con los valores númericos de tasas de aprendizaje \n",
    "        para realizar los experimentos\n",
    "    grados: Es una lista con los valores númericos de grados \n",
    "        para realizar los experimentos\n",
    "    retorna: un dataframe con el resultados de los experimentos\n",
    "    \"\"\"\n",
    "    numero_iter = 50\n",
    "\n",
    "    resultados = pd.DataFrame()\n",
    "    idx = 0 # indice\n",
    "    for eta in tasas:\n",
    "        for grado in grados:\n",
    "            W,scaler = \n",
    "            error_entrenamiento = \n",
    "            error_prueba = \n",
    "                        \n",
    "            resultados.loc[idx,'grado'] = grado\n",
    "            resultados.loc[idx,'tasa de aprendizaje'] = eta\n",
    "            resultados.loc[idx,'error_entreamiento'] = error_entrenamiento\n",
    "            resultados.loc[idx,'error_prueba'] = error_prueba\n",
    "            idx = idx+1\n",
    "\n",
    "    return (resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4Y2qwvnYyTL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## la funcion que prueba tu implementacion\n",
    "GRADER.run_test(\"ejercicio2.5\", experimentar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNZ702IVYyTN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasas = [1,0.1,0.001]\n",
    "grados = [1,2,3,4,5]\n",
    "resultados = experimentar (Xtrain, Xtest, Ytrain, Ytest, tasas, grados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i0S18dT2YyTO"
   },
   "outputs": [],
   "source": [
    "# para ver los resultados\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "2o0zE_e7YyTS"
   },
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown  ¿con base a los resultados anteriores, qué efecto tiene el grado en los errores de entrenamiento y de prueba? justifique\n",
    "respuesta_4 = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "Z8waNHm0YyTT"
   },
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown  ¿es normal que los errores de entrenamiento y prueba sean diferentes? justifique\n",
    "respuesta_5 = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mnhcuVcTYyTV"
   },
   "outputs": [],
   "source": [
    "def numero_de_errores (W, X, Y, grado, scaler):\n",
    "    \"\"\"función que cuenta los errores de un modelo de regresión logistica\n",
    "    W: vector con los parametros de un modelo de regresión logistica\n",
    "       previamente entrenado\n",
    "    X: conjunto de datos a usar (numpy matrix)\n",
    "    Y: conjunto con las etiquetas verdaderas. (numpy array)\n",
    "    grado: grado usado en el modelo de regresión logistica\n",
    "    retorna: numero de errores (int/float) \n",
    "            (es decir el numero de veces que la etiqueta predicha es diferente a la etiqueta real)\n",
    "    \"\"\"\n",
    "    X2 = potenciaPolinomio(X,grado)\n",
    "    X2 = scaler.transform(X2)\n",
    "    Y_estimado = np.round(logistic_regression(MatrizExtendida(X2),W))\n",
    "    numero_errores = np.sum(Y_estimado!=Y)\n",
    "\n",
    "    return numero_errores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-bRi6p6YyTY"
   },
   "source": [
    "Ahora, use las funciones que ha creado, entrene nuevamente un modelo con los mejores parametros obtenidos y calcule cuantas muestras quedaron mal clasificadas tanto en el conjunto de entrenamiento, como en el de prueba. Use la función numero_de_errores.\n",
    "\n",
    "Si hay parametros empatados, el modelo que tenga menos parametros deberia ser el mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-LG4-DhYyTY"
   },
   "outputs": [],
   "source": [
    "# Puede usar el siguiente código para ordenar los resultados y ver los 3 primeros\n",
    "# resultados, use esta salida para ver cuales fueron los mejores parámetros\n",
    "resultados.sort_values(by = ['error_prueba', 'grado'], ascending = True).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q81OIPYJYyTa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "W,scaler = gradiente_descendente_logistic_poly(Xtrain,Ytrain,grado = 2  ,eta = 1, iteraciones = 50)\n",
    "print(\"estos son los pesos para el modelo entrenando \\n\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VpRyLulYyTb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_errores_entrenamiento =  numero_de_errores (W, Xtrain, Ytrain, 2, scaler)\n",
    "num_errores_prueba =  numero_de_errores (W, Xtest, Ytest, 2, scaler)\n",
    "print(\"muestras mal clasificadas en entrenamiento\", num_errores_entrenamiento)\n",
    "print(\"muestras mal clasificadas en pruebas\", num_errores_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "ZnGyv4JtYyTd"
   },
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown ¿por qué se uso el error de prueba para ordenar la tabla de resultados en lugar del error de entrenamiento?\n",
    "respuesta_6 = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "ANlQQocoYyTf"
   },
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown Escribe aqui el numero de muestras que quedaron mal clasificadas en el conjunto de entrenamiento y de pruebas. ¿como calificarias el modelo entrenado?\n",
    "respuesta_7 = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "2FZeWG54YyTg"
   },
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown Escriba el modelo completo con sus variables y coeficientes de f(**x**,**w**) con la mejor frontera de decisión que encontró. usa los valores del último W entrenado. Recuerda tener presente el grado del polinomio\n",
    "respuesta_8 = \"0.0x1 + 1.0x1**2 + 2.0x2 + 3.0x2**3\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qdlLAktOYyTh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "GRADER.check_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "U0DWcBDcYyTj"
   },
   "outputs": [],
   "source": [
    "#@title Integrantes\n",
    "codigo_integrante_1 ='' #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19FgbUXzYyTl"
   },
   "source": [
    "----\n",
    "Esta linea es de uso exclusivo del los profesores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KepG_JTvYyTl"
   },
   "outputs": [],
   "source": [
    "GRADER.grade()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "lab1_parte2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
